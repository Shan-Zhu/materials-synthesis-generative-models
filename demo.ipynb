{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Demo for *Inorganic materials synthesis planning with literature-trained neural networks*\n",
    "\n",
    "This notebook provides a tutorial for the word embeddings and machine learning models in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First: download additional resources\n",
    "\n",
    "### FastText\n",
    "- [Trained model](https://figshare.com/s/70455cfcd0084a504745)\n",
    "\n",
    "### ELMo\n",
    "- [Vocabulary file](https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/vocab-2016-09-10.txt)\n",
    "- [Weights and config](https://figshare.com/s/ec677e7db3cf2b7db4bf)\n",
    "- [bilm-tf Library](https://github.com/allenai/bilm-tf)\n",
    "\n",
    "For the `bilm-tf` library, you'll need to run through the setup instructions. In practice, we've found that ELMo performs much better than FastText in a variety of tasks (e.g., named entity recognition), but it has much higher computational cost and requires GPUs.\n",
    "\n",
    "For the FastText model files and the ELMo weights/options, place them in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries\n",
    "\n",
    "Import the following libraries, and `pip install` or `conda install` anything that you don't have. Some of these libraries are used in the `models` folder and not directly in this notebook, but it's easier to check these dependencies first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import keras\n",
    "import tensorflow\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FastText Embeddings for Materials Science\n",
    "\n",
    "FastText embeddings allow for out-of-vocabulary inference by using sub-word information. Our FastText model is trained to use lowercase letters only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = gensim.models.keyedvectors.KeyedVectors.load(\"../synthesis-generation/bin/fasttext_embeddings-MINIFIED.model\")\n",
    "\n",
    "# Need to set this when loading from saved file\n",
    "fasttext.bucket = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407776617325483\n",
      "0.8053306072499058\n",
      "0.7119846415681294\n",
      "0.7841045911308067\n"
     ]
    }
   ],
   "source": [
    "# Examples that should have reasonably high similarity\n",
    "\n",
    "print(fasttext.similarity(\"batio3\", \"bifeo3\"))\n",
    "print(fasttext.similarity(\"rinse\", \"wash\"))\n",
    "print(fasttext.similarity(\"grind\", \"mill\"))\n",
    "print(fasttext.similarity(\"nanotube\", \"nanosphere\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "(100,)\n",
      "0.6120179766407703\n",
      "0.46709642006346813\n"
     ]
    }
   ],
   "source": [
    "# Out-of-vocabulary inference\n",
    "# A new vector is inferred for an unseen material and\n",
    "# reasonable similarity estimates are produced\n",
    "\n",
    "print(\"licoo2\" in fasttext.vocab)\n",
    "print(\"lini(1窶度)coxo2\" in fasttext.vocab)\n",
    "\n",
    "print(fasttext[\"lini(1窶度)coxo2\"].shape)\n",
    "\n",
    "print(fasttext.similarity(\"licoo2\", \"lini(1窶度)coxo2\"))\n",
    "print(fasttext.similarity(\"mno2\", \"lini(1窶度)coxo2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ELMo Embeddings for Materials Science\n",
    "\n",
    "ELMo embeddings are context-sensitive at prediction time, in addition to being fully character-based. This means that out-of-vector inference is possible at prediction time, and both upper and lower case letters are supported.\n",
    "\n",
    "Support for ELMo embeddings is provided through our custom `TokenClassifier` object (which can also perform NER, once trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/synthesisproject/anaconda3/lib/python3.6/site-packages/bilm-0.1.post5-py3.6.egg/bilm/model.py:384: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "USING SKIP CONNECTIONS\n"
     ]
    }
   ],
   "source": [
    "from models import token_classifier\n",
    "token_classifier = token_classifier.TokenClassifier(\n",
    "    vocab=\"../synthesis-generation/bin/vocab.txt\", \n",
    "    options=\"../synthesis-generation/bin/elmo_options.json\", \n",
    "    weights=\"../synthesis-generation/bin/elmo_weights.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    [\"The\", \"silica\", \"nanoparticles\", \"were\", \"heated\", \".\"],\n",
    "    [\"The\", \"precursor\", \"was\", \"sputtered\", \"onto\", \"the\", \"silica\", \"substrate\", \".\"]\n",
    "]\n",
    "\n",
    "feature_matrix = token_classifier.featurize_elmo_list(example_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silica\n",
      "silica\n"
     ]
    }
   ],
   "source": [
    "print(example_sentences[0][1])\n",
    "print(example_sentences[1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7241073\n"
     ]
    }
   ],
   "source": [
    "# Since ELMo is context-sensitive, it can produce different embeddings for the same word (\"silica\")\n",
    "\n",
    "silica_embedding_1 = feature_matrix[0][1]\n",
    "silica_embedding_2 = feature_matrix[1][6]\n",
    "\n",
    "print (numpy.linalg.norm(silica_embedding_1 - silica_embedding_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading and building variational autoencoder models\n",
    "\n",
    "The code samples below show how to load and inspect the Keras models included in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import action_generator, material_generator\n",
    "\n",
    "action_generator = action_generator.ActionGenerator()\n",
    "material_generator = material_generator.MaterialGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ops_in (InputLayer)             (None, 20, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_1 (Conv1D)             (None, 16, 128)      32128       ops_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_2 (Conv1D)             (None, 12, 128)      82048       conv_enc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_3 (Conv1D)             (None, 8, 128)       82048       conv_enc_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           conv_enc_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc (Dense)              (None, 128)          131200      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "means_enc (Dense)               (None, 8)            1032        hidden_enc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "vars_enc (Dense)                (None, 8)            1032        hidden_enc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_sample (Lambda)          (None, 8)            0           means_enc[0][0]                  \n",
      "                                                                 vars_enc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cond_matrl_in (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat_cond (Concatenate)       (None, 108)          0           lambda_sample[0][0]              \n",
      "                                                                 cond_matrl_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec (Dense)              (None, 128)          13952       concat_cond[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "h_rep_dec (RepeatVector)        (None, 20, 128)      0           hidden_dec[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_1 (GRU)           (None, 20, 64)       37056       h_rep_dec[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_2 (GRU)           (None, 20, 64)       24768       recurrent_dec_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_3 (GRU)           (None, 20, 64)       24768       recurrent_dec_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "means_op_dec (TimeDistributed)  (None, 20, 50)       3250        recurrent_dec_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 433,282\n",
      "Trainable params: 433,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "action_generator.build_nn_model()\n",
    "action_generator.vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "material_in (InputLayer)        (None, 10, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_1 (Conv1D)             (None, 8, 64)        9664        material_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_2 (Conv1D)             (None, 6, 64)        12352       conv_enc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_enc_3 (Conv1D)             (None, 4, 64)        12352       conv_enc_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           conv_enc_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "hidden_enc (Dense)              (None, 64)           16448       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "means_enc (Dense)               (None, 8)            520         hidden_enc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "vars_enc (Dense)                (None, 8)            520         hidden_enc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_sample (Lambda)          (None, 8)            0           means_enc[0][0]                  \n",
      "                                                                 vars_enc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cond_latent_recipe_in (InputLay (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cond_element_in (InputLayer)    (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat_cond (Concatenate)       (None, 119)          0           lambda_sample[0][0]              \n",
      "                                                                 cond_latent_recipe_in[0][0]      \n",
      "                                                                 cond_element_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_dec (Dense)              (None, 64)           7680        concat_cond[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "h_rep_dec (RepeatVector)        (None, 10, 64)       0           hidden_dec[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_1 (GRU)           (None, 10, 64)       24768       h_rep_dec[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_2 (GRU)           (None, 10, 64)       24768       recurrent_dec_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_dec_3 (GRU)           (None, 10, 64)       24768       recurrent_dec_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "means_material_dec (TimeDistrib (None, 10, 50)       3250        recurrent_dec_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 137,090\n",
      "Trainable params: 137,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "material_generator.build_nn_model()\n",
    "material_generator.vae.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
